Unless otherwise specified, in the following $R = (R,+,\cdot)$ denotes an arbitrary ring \emph{with identity}, $0, 1$ denotes the additive and multiplicative identity of $R$, respectively. In the case of possible confusion, I will use $0_R, 1_R$ instead. 

Some description and hints are omitted for simplicity.

\section{}

\begin{problem}{III.1.1}
Prove that if $0 = 1$ in a ring $R$, then $R$ is a zero ring.
\end{problem}
\begin{pf}
If $r$ is any nonzero element in $R$, then
\[
r = r \cdot 1 = r \cdot 0 = 0  
\]
showing that $R = 0$.
\end{pf}
\begin{problem}{III.1.6}
Prove that if $a$ and $b$ are nilpotent in $R$ and $ab = ba$, then so is $a+b$.
\end{problem}
\begin{pf}
If $a^n = 0, b^m = 0$, then
\[
(a+b)^{n+m} = a^{n+m} +\binom{n+m-1}{1} a^{n+m-1}b + ... + b^{n+m}
\]
and all terms are zeros since every term either have $a^n$ or $b^m$. If we do not assume that $ab = ba$, then the statement would be false, for example, in $M_n(\mathbb{Z})$,
\[
\begin{pmatrix} 
1 & 0 \\
1 & 0
\end{pmatrix}
\quad \text{and} \quad
\begin{pmatrix} 
0 & 1 \\
0 & 1 
\end{pmatrix}
\]
are nilpotent of degree $3$, but
$\begin{pmatrix} 
1 & 0 \\
1 & 0
\end{pmatrix} + 
\begin{pmatrix} 
0 & 1 \\
0 & 1 
\end{pmatrix} = 
\begin{pmatrix} 
1 & 1 \\
1 & 1
\end{pmatrix}$, which is not nilpotent.
\end{pf}

\begin{problem}{III.1.7}
Prove that $[m]$ is nilpotent in $\Z/n\Z$ if and only if $m$ is divisible by all prime factors of $n$. 
\end{problem}
\begin{pf}

\noindent $(\Rightarrow)$ If $[m]^k = [0]$ for some integer $k$, then this implies $m^k = dn$ for some integer $d$. Now we write $n = p_1^{a_1} \cdots p_n^{a_n}$, where $p_i$ are primes, and $a_i$ are positive integers. Then
\[
m^k = d p_1^{a_1} \cdots p_n^{a_n}
\]
and it is clear to see that $m$ must contain each $p_i$ at least once. \\
$(\Leftarrow)$ If $n = p_1^{a_1} \cdots p_n^{a_n}$ where $p_i$ are primes, and $a_i$ are positive integers, then we can write 
\[
m = p_1^{b_1} \cdots p_n^{b_n} d
\] 
where $b_i, d$ are positive integers, and $p_i \nmid d$ for all $i$. Define 
\[
f = \text{floor}\left(\max\left\{ \frac{a_1}{b_1}, \cdots \frac{a_n}{b_n}\right\} \right)    
\]
then let $r = m^f/n$, which is an integer larger than 0 by the choice of $f$. Finally
\[
m^f = nr = 0 \mod n
\]
showing that $m$ is nilpotent in $\Z/n\Z$.
\end{pf}

\begin{problem}{III.1.9}
Prove Proposition 1.12, that is:
\begin{itemize}
\setlength\itemsep{0pc}
\item The inverse of a two-sided unit is unique;
\item two-sided units form a group under multiplication.
\end{itemize}
\end{problem}
\begin{pf}
For a two-sided unit $v$, we have $uv = 1$ and $vw = 1$ for some $u,w \in R$. Then 
\[
w = 1 \cdot w = uvw = u \cdot 1 = u    
\]
showing that $w = u$, so the inverse can be uniquely defined as $v^{-1} = u$. Now as the inverse is unique, we can properly define a group structure, using the multiplication from the ring $R$.
\end{pf}

\begin{problem}{III.1.15}
Prove that $R[x]$ is a domain \iffw $R$ is a domain.
\end{problem}
\begin{pf}

\noindent $(\Rightarrow)$ Trivial since $R \subset R[x]$. \\
$(\Leftarrow)$ Assume the contrary that $R[x]$ is not a domain. Then we can find $f = \sum_{i=0}^n a_ix^i, \: g = \sum_{j=0}^m b_jx^j$, $f \neq 0, g \neq 0$ such that $fg = 0$. Then we would have $a_nb_m = 0$, and since $R$ is a domain, either $a_n$ or $b_m$ is zero. Without loss of generality, we can reduce the case to $f = a_0 \neq 0$. Then by the same argument, we would arrive at $a_0b_0 = 0$, since all higher terms must be zero. But this contradict to the assumption that $R$ is a domain, since $f = a_0$ and $g = b_0$ are nonzero. Hence $R[x]$ must be a domain.
\end{pf}

\section{}
\begin{problem}{III.2.1}
Prove that if there is a homomorphism from a zero ring to a ring $R$, then $R$ is a zero ring.
\end{problem}
\begin{pf}
If $1_R$ is the multiplicative identity of $R$, then for any homomorphism $\varphi : 0 \to R$, 
\[
0_R = \varphi(0) = \varphi(1) = 1_R
\]
and by III.1.1, $R$ is a zero-ring.
\end{pf}

\begin{problem}{III.2.6}
Verify the 'extension property' of polynomial ring:

Let $\alpha : R \to S$ be a fixed ring homomorphism, and let $s \in S$ be an element commuting with $\alpha(r)$ for all $r \in R$. Then there is a unique ring homomorphism $\bar{\alpha} : R[x] \to S$ extending $\alpha$ and sending $x$ to $s$.
\end{problem}
\begin{pf}
Indeed, for $\sum_{i \geq 0} a_ix^i \in R[x]$, we have no choice but to define
\[
\bar{\alpha}\left(\sum_{i \geq 0} a_ix^i\right) = \sum_{i \geq 0}\alpha(a_i)s^{i}  \tag{1}
\]
so that $\bar{\alpha}(r) = \alpha(r)$ and $x$ sends to $s$ in this map. It is clearly a homomorphism (note that the commutativity of $s$ is used in the proof of $\bar{\alpha}(fg) = \bar{\alpha}(f)\bar{\alpha}(g)$), so it suffices to check that $\bar{\alpha}$ is unique. But it is clear by the fact that any map that extends $\alpha$ and send $x$ to $s$ must have the same value evaluated as in $(1)$.
\end{pf}

\begin{problem}{III.2.9}
Prove that the center of $R$ is a subring. Moreover, prove that the center of a division ring is a field.
\end{problem}
\begin{pf}
A subset of a ring $S$ is a subring if it is a subgroup of $(R,+)$, closed under multiplication, and $1$ is in it. So we check that:
\begin{itemize}
\setlength\itemsep{0pt}
\item it is a subgroup of $(R,+)$: for $a,b \in C$, for all $r \in R$,
\[
(a-b)r = ar - br = ra - rb = r(a-b)    
\]
showing that $a-b \in C$, hence a subgroup;
\item closed under multiplication: for $a,b \in C$, for all $r \in R$,
\[
abr = a(br) = a(rb) = (ar)b = (ra)b = rab     
\]
showing that $ab \in C$;
\item finally, $1$ is in $C$ since $1r = r1$ for all $r \in R$.
\end{itemize}


Clearly the center forms a commutative ring since for $a,b \in C$, $ab = ba$. Then it follows by definition that a commutative division ring is a field. 
\end{pf}

\begin{problem}{III.2.10}
Prove that the centralizer of $a$ is a subring for every $a \in R$. Prove that the center is the intersection of all its centralizers, and prove that every centralizer of a division ring is a division ring.
\end{problem}
\begin{pf}
We use the same test as above. Let $C_x$ denotes the centralizer of $x$.
\begin{itemize}
\setlength\itemsep{0pt}
\item It is a subgroup of $(R,+)$: for $a,b \in C_x$,
\[
(a-b)x = ax - bx = xa - xb = x(a-b)    
\]
showing that $a-b \in C_x$, hence a subgroup;
\item closed under multiplication: for $a,b \in C_x$,
\[
abx = a(bx) = a(xb) = (ax)b = (xa)b = xab     
\]
showing that $ab \in C_x$;
\item finally, $1$ is in $C_x$ since $1x = x1$.
\end{itemize}
It is easy that the center is the intersection of all its centralizers, since such elemet in the intersection must commute with the whole ring $R$. Finally, if $R$ is a division ring, then for every element $a \in C_x$, then we show that $a^{-1} \in C_x$:
\[
ax = xa \Rightarrow axa^{-1} = x \Rightarrow xa^{-1} = a^{-1}x
\]
as desired.
\end{pf}

\begin{problem}{III.2.11}
Prove that a division ring $R$ which consists of $p^2$ elements where $p$ is a prime, is commutative. 
\end{problem}
\begin{pf}
Suppose the contrary that $R$ is not commutative. Then the center $C$ must be a proper subring, which can only consist of $p$ elements by Lagrange. Now let $r \in R \backslash C$. Then the centralizer of $r$ will contain at least $r$ and $C$ by III.2.10, therefore the centralizer of $r$ must be $R$ itself (again by Lagrange), for every $r \in R \backslash C$. But then the intersection of all centralizer are now $R$ (element of center has centralizer $R$ clearly), which is a contradiction to that $C$ is proper. Therefore $R$ must be commutative, i.e. a field.
\end{pf}

\begin{problem}{III.2.12}
Consider the inclusion map $\iota : \Z \xhookrightarrow{} \Q$. Describe the cokernel of $\iota$ in \textsf{Ab} and its cokernel in \textsf{Ring}.
\end{problem}
\begin{sol}
In \textsf{Ab}, this is easy: it is just $\Q/\im \iota = \Q / \Z$. However in \textsf{Ring}, we notice that for any map $\alpha : \Q \to F$ that satisfy $\alpha \circ \iota = 0$, we have
\[
0_F = \alpha (1) = \alpha \circ \iota (1) = \alpha (1) = 1_F  
\] 
which shows that $F$ must be the zero ring by III.1.1. Now the unique homomorphism $\bar{\alpha} :\text{coker } \iota \to F$ must also be the zero map, and by the requirement $\bar{\alpha} \circ \pi \circ \iota = 0$, we finally have $\pi \circ \iota = 0$, and by the same argument as above, we have that the codomain of $\pi$ is the zero ring, i.e. $\text{coker } \iota = 0$.
\end{sol}

\section{}

\begin{problem}{III.3.2}
Let $\varphi:R \to S$ be a ring homomorphism, and let $J$ be an ideal of $S$. Prove that $\varphi^{-1}(J)$ is an ideal.
\end{problem}
\begin{pf}
The ideal is clearly nonempty, so it suffices to check that $\varphi^{-1}(J)$ is a additive subgroup and satisfies the absorption property. For $x, y \in \varphi^{-1}(J)$, we have $\varphi(x), \varphi(y) \in J$, so $\varphi(x)-\varphi(y) = \varphi(x-y) \in J$, therefore $x-y \in \varphi^{-1}(J)$, showing that it is a subgroup of $(R,+)$.

Now for any $r \in R, a \in \varphi^{-1}(J)$, we have $\varphi(a) \in J$, so $\varphi(r)\varphi(a) = \varphi(ra) \in J$, and hence $ra \in \varphi^{-1}(J)$, showing the left-absorption property. The right case is the same.
\end{pf}

\begin{problem}{III.3.3}
Let $\varphi : R \to S$ be a ring homomorphism, and let $J$ be an ideal of $R$.
\end{problem}
\begin{itemize}
\setlength\itemsep{0pt}
\item Show that $\varphi(J)$ need not be an ideal of $S$.
\item Assume that $\varphi$ is surjective; then prove that $\varphi(J)$ \emph{is} an ideal of $S$.
\item Assume that $\varphi$ is surjective, and let $I = \ker \varphi$. Let $\bar{J} = \varphi(J)$. Prove that 
\[
\frac{R/I}{\bar{J}} \cong \frac{R}{I+J}.	
\]
\end{itemize}
\begin{pf}
Let $\varphi : \Z \xhookrightarrow{} \R$ be inclusion (and clearly a homomorphism). Then every ideal of $\Z$ will be directly transformed into $\R$. But since $\R$ is a field, by III.3.8 (which will be proved later) the possible ideal of $\R$ are only $\{0\}$ and $\R$ itself, so the image of a homomorphism need not to be an ideal.

However, If $\varphi$ is surjective, Then $\varphi(J)$ is indeed an ideal: if $\varphi(x), \varphi(y) \in \varphi(J)$, then so is $\varphi(x) - \varphi(y) = \varphi(x-y) \in \varphi(J)$. The absorption property is also true since $\varphi(r)\varphi(x) = \varphi(rx) \in \varphi(J)$.

Finally, we consider the homomorphism
\[
\phi : R/I \to R/(I+J), \quad \phi(a + I) = a + I + J
\]
$\phi$ is clearly a surjective homomorphism, and by first isomorphism theorem
\[
\frac{R/I}{\ker \phi} \cong \frac{R}{I+J}	
\]
so it remains to solve $\ker \phi$, which is
\begin{align*}
\ker \phi &= \{a + I : a + I + J = I + J\} \\
&= \{a +b + I : a \in I, b \in J\} \\
&= \{b + I : b \in J\} \\
&= \{\varphi(b) \in S : b \in J\} \quad \text{(regarding } R/I \text{ as } S)\\
&= \varphi(J) = \bar{J}
\end{align*}
therefore
\[
\frac{R/I}{\bar{J}} \cong \frac{R}{I+J}
\]
as required.
\end{pf}

\begin{problem}{III.3.7}
Let $R$ be a ring, and let $a \in R$. Prove that $Ra$ is a left-ideal of $R$ and $aR$ is a right-ideal of $R$. Prove that $a$ is a left-, resp. right-, unit if and only if $R = aR$, resp. $R = Ra$.
\end{problem}
\begin{pf}
We prove only the left-ideal case since the same argument holds for right-ideal case. $Ra$ is a subgroup of $(R,+)$ since for $ra, sa \in Ra$, $ra - sa = (r-s)a \in Ra$. The absorption property follows easily since $rsa = (rs)a \in Ra$.

If $a$ is a right unit, then there exists $u$ such that $ua = 1$. Then $1$ is contained in $Ra$, and since for all $r\in R$, $r \cdot 1 \in Ra$, we conclude that $R = Ra$.   
\end{pf}

\begin{problem}{III.3.8}
Prove that $R$ is a division ring \iffw its only left-ideals and right-ideals are $\{0\}$ and $R$.

In particular, a commutative ring $R$ is a field if and only if the only ideals of $R$ are $\{0\}$ and $R$.
\end{problem}
\begin{pf}

\noindent $(\Rightarrow)$ If a nonzero element $a$ is in the left-ideal $I$, then so is $1$ since 
\[
1 = a^{-1}a \in I \text{ by definition}
\] 
Therefore any nonzero left-ideals are automatically $R$ itself. The right-ideal case is the same.

\noindent $(\Leftarrow)$ If a nonzero element $a$ does not have a left inverse, then $aR$ would be a proper right-ideal by III.3.7. Therefore all elements must have left(and hence right) inverse.
\end{pf}

\begin{problem}{III.3.10}
Let $\varphi : k \to R$ be a ring homomorphism, where $k$ is a field and $R$ is a nonzero ring. Prove that $\varphi$ is \emph{injective}.
\end{problem}
\begin{pf}
$\varphi$ is injective if and only if $\ker \varphi = \{0\}$ by Proposition III.2.4. Also, the ideals of $k$ are only $\{0\}$ and $k$ by III.3.8. If $\ker \varphi = \{0\}$ then there is nothing to prove, so let $\ker \varphi = k$. But this means that $\varphi = 0$, so we have
\[
1_R = \varphi(1) = 0 = \varphi(0) = 0_R    
\]
and by III.1.1, $R$ is a zero ring, a contradiction to the hypothesis. Therefore $\ker \varphi = \{0\}$, showing that $\varphi$ is injective.
\end{pf}


\begin{problem}{III.3.12}
Let $R$ be a \emph{commutative} ring. Prove that the set of nilpotent elements forms an ideal of $R$. This ideal is called the \emph{nilradical} of $R$.
\end{problem}
\begin{pf}
From III.1.6 we already know that it forms a subgroup of $(R,+)$ by relpacing b with $-b$, so it remains to check that it is an ideal. Let $I$ be such ideal. If $a \in R, r \in I$ and $r^n = 0$, then since
\[
(ar)^n \overset{!}{=} a^nr^n = 0    
\]
in which ! is where commutative is used. Therefore $ar \in I$, proving the absorption property.

For an counter-example where $R$ is not commutative, simply consider the example of III.1.6: it is not even a subgroup of $(R, +)$.
\end{pf}

\begin{problem}{III.3.13}
Let $R$ be a commutative ring, and let $N$ be its nilradical. Prove that $R/N$ contains no nonzero nilpotent elements. Such a ring is said to be \emph{reduced}.
\end{problem}
\begin{pf}
Pick an element $a \in R \backslash N$. Then for every integer $n > 0$, 
\[
(a + N)^n = a^n + \binom{n}{1} a^{n-1} N + \cdots + N^n = a^n + N
\]
Since $a$ is not nilpotent, $a^n \neq 0$ for every $n$, showing that $a + N$ is not nilpotent for $a \in R \backslash N$.
\end{pf}

\section{}
\begin{problem}{III.4.1}
Let $R$ be a ring, and let $\{I_\alpha\}_{\alpha \in A}$ be a family of ideals of $R$. We let 
\[
\sum_{\alpha \in A} I_\alpha := \left\{ \sum_{\alpha \in A}r_\alpha \text{ such that } r_\alpha \in I_\alpha \text{ and } r_\alpha = 0 \text{ for all but finitely many } \alpha \right\}.  
\]
Prove that $\{I_\alpha\}_{\alpha \in A}$ is an ideal of $R$ and that it is the smallest ideal containing all of the ideals $I_\alpha$.
\end{problem}
\begin{pf}
We only consider the case when $A = \{1,2\}$: Any other $A$ follows the same exact argument. 

Let $I = I_1 + I_2$. $I$ is a subgroup of $(R,+)$ : the two elements in $I$ can be represented as $r_1 + r_2$ and $r'_1 + r'_2$, and clearly $(r_1 - r'_1) + (r_2 - r'_2)$ is in $I$. The absorption property is also clear, since $r (r_1 + r_2) = (rr_1 + rr_2) \in I$. 

Now it suffice to show that $I$ is minimal. For every ideal that contains $I_1$ and $I_2$, they must also contain $r_1 + r_2$ for $r_1 \in I_1$ and $r_2 \in I_2$, since ideal is a subgroup of $(R,+)$. Therefore every such ideal must also contain $I$, proving the minimality of $I$.
\end{pf}

\begin{problem}{III.4.2}
Prove that the homomorphic image of a Noetherian ring is Noetherian.
\end{problem}
\begin{pf}
Let $R$ be Noetherian, $S$ be any ring, $\varphi:R \to S$ be a surjective ring homomorphism. Let $J$ be an ideal of $S$. By III.3.2, the preimage is an ideal, which we call $I = \langle a_1, ... a_n \rangle$. We claim that $J = \langle \varphi(a_1), ... \varphi(a_n) \rangle$, so every finitely generated ideal will map to a finitely generated ideal, proving that $S$ is Noetherian. 

Indeed, since $a_i \in \varphi^{-1}(J)$, $\varphi(a_i) \in J$ for $i = 1,...,n$, so $\langle \varphi(a_1), ... \varphi(a_n) \rangle \subseteq J$. On the other hand, for an element $j \in J$, there exists $i \in R$ such that $\varphi(i) = j$ by surjectivity, therefore $i \in I$, so $i$ is generated by elements $a_1, ... ,a_n$, i.e. $i = r_1a_1 + ... + r_na_n$. Then since $\varphi$ is a homomorphism, 
\[
\varphi(i) = j = \varphi(r_1a_1 + ... + r_na_n) = s_1\varphi(a_1) + ... + s_n\varphi(a_n)
\]
so $J \subseteq \langle \varphi(a_1), ... \varphi(a_n) \rangle$, and the claim is proved.
\end{pf}

\begin{problem}{III.4.4}
Prove that if $k$ is a field, then $k[x]$ is a PID.
\end{problem}
\begin{pf}
Let $I$ be any ideal of $k[x]$. If $I = (0)$, then there is nothing to prove. Otherwise, there is some polynomial $f\in I$ that has minimal degree in $I$ and is monic (since you can do scalar division). We claim that $I = (f)$. Indeed, for $g \in I$, we can use division algorithm to write
\[
g(x) = f(x)q(x) + r(x)  
\]  
where $\deg r(x) < \deg f(x)$. Since $k[x]$ is a subgroup, $r = g - fq \in I$, and by the minimality of $f$, $r(x) = 0$, so every element of $I$ can be written as $g(x)f(x)$ for some $g \in k[x]$, showing that $k[x]$ is a PID.
\end{pf}

\begin{problem}{III.4.5}
Let $I, J$ be ideals in a commutative ring $R$, such that $I+J = (1)$. Prove that $IJ = I \cap J$.
\end{problem}
\begin{pf}
If $x \in IJ$, then it can be represented as $ij$ for some $i \in I, j \in J$, and by the property of ideal, $ji \in I, ij \in J$, so $ij \in I \cap J$. Conversely, we have
\[
I \cap J = (I \cap J) (1) = (I\cap J)(I+J) = (I \cap J)I + (I \cap J)J \subseteq IJ + IJ = IJ 
\]
showing the identity.
\end{pf}

\begin{problem}{III.4.7}
Let $R = k$ be a field. Prove that every nonzero (principle) ideal in $k[x]$ is generated by a unique \emph{monic} polynomial.
\end{problem}
\begin{pf}
From III.4.4 we already know that every ideal is generated by a single polynomial $f$. Since $k$ is a field, we can do division, so there is a monic polynomial $f(x)/a$ where $a$ is the coefficient of the largest degree in $f$. Then it's trivial that $(f) = (f/a)$.
\end{pf}

\begin{problem}{III.4.11}
Let $R$ be a commutative ring, $a \in R$, and $f_1(x),\dotsc,f_r(x) \in R[x]$.
\begin{itemize}
\setlength\itemsep{0pt}
\item Prove the equality of ideals
\[
(f_1(x),\dotsc,f_r(x),x-a) = (f_1(a),\dotsc,f_r(a),x-a).
\]
\item Prove the useful substitution trick
\[
\frac{R[x]}{(f_1(x),\dotsc,f_r(x),x-a)} \cong \frac{R}{(f_1(a),\dotsc,f_r(a))}
\]
\end{itemize}
\end{problem}
\begin{pf}
We consider only the case $k = 1$; the other cases are just extending the same argument. We are required to prove that 
\[
(f(x), x-a) = (f(a), x-a)
\]
For $f(x)$, we can apply division algorithm to get
\[
f(x) = q(x)(x-a) + r
\]
where $q(x) \in R[x], r \in R$. By plug in $x = a$, we obtain $r = f(a)$. Therefore $f(x)$ is generated by $f(a)$ and $(x-a)$, showing $f(x)\in (f(a), x-a)$. On the other hand, note the division algorithm also implies
\[
f(a) = f(x) - q(x)(x-a) \in (f(x), x-a)
\]
therefore $f(a) \in (f(x), x-a)$, so $(f(x), x-a) = (f(a), x-a)$. Now since $R[x]/(x-a) \cong R$, by III.3.3
\[
\frac{R}{\varphi(J)} \cong \frac{R[x]}{\ker \varphi + J}	
\]
for an ideal $J \in R[x]$, $\varphi : R[x] \to R$ a surjective homomorphism. It is clear that how should we choose these: by taking
\[
J = (f_1(x),\dotsc,f_r(x)), \quad \varphi(f(x)) = f(a)	
\]
we have
\[
\frac{R}{(f_1(a),\dotsc,f_r(a))} \cong \frac{R[x]}{(f_1(x),\dotsc,f_r(x),x-a)} 
\]
as desired (note that $\varphi$ is surjective).
\end{pf}

\begin{problem}{III.4.13}
Let $R$ be an integral domain. For all $k = 1,\dotsc, n$, prove that $(x_1,\dotsc, x_k)$ is prime in $R[x_1,\dotsc, x_n]$.
\end{problem}
\begin{pf}
We proceed by induction. For the case $k = 1$, we have
\[
\frac{R[x]}{(x)} \cong R	\quad \text{(p.p.151)}
\]
and since $R$ is a domain, it follows by definition that $(x)$ is a prime ideal. Suppose that for $k < n$, the argument holds. Then for $k = n$, choose
\[
J = (x_1,\dotsc,x_{n-1}), \quad \varphi : R[x_1,\dotsc,x_{n}] \xhookrightarrow{} R[x_1,\dotsc,x_{n-1}]
\]
where $\varphi$ is the inclusion map and $\ker \varphi = (x_n)$. Then by III.3.3
\[
\frac{R[x_1,\dotsc,x_{n}]/(x_n)}{(x_1,\dotsc,x_{n-1})} \cong \frac{R[x_1,\dotsc,x_{n}]}{(x_1,\dotsc,x_{n-1})+(x_n)}
\]
which simplifies to
\[
\frac{R[x_1,\dotsc,x_{n-1}]}{(x_1,\dotsc,x_{n-1})} \cong \frac{R[x_1,\dotsc,x_{n}]}{(x_1,\dotsc,x_n)}	
\]
By induction hypothesis, the quotient on the left is a domain since $(x_1,\dotsc,x_{n-1})$ is a prime ideal, therefore by definition, $(x_1,\dotsc,x_n)$ is a prime ideal.
\end{pf}


\begin{problem}{III.4.16}
Let $R$ be a commutative ring, and let $P$ be a prime ideal of $R$. Suppose $0$ is the only zero-divisor of $R$ contained in $P$. Prove that $R$ is an integral domain. 
\end{problem}
\begin{pf}
Let $a,b \in R$ such that $ab = 0$. Then since $0 \in P$, $ab \in P$, so either $a\in P$ or $b \in P$. Without loss of generality, let $a \in P$. If $a = 0$, then we are done; otherwise, $a \neq 0$, and since $ab = 0$, we must have $b = 0$ as $a$ is not a zero divisor ($0$ is the only zero-divisor in $P$). In both cases, we show that $ab = 0$ implies $a = 0$ or $b = 0$, showing that $R$ is a domain.
\end{pf}

\begin{problem}{III.4.18}
Let $R$ be a commutative ring, and let $N$ be its nilradical (III.3.12). Prove that $N$ is contained in every prime ideal of $R$.
\end{problem}
\begin{pf}
Let $x^n = 0$ for some positive integer $n$, and $P$ a prime ideal. Then since $0 \in P$, we have
\[
P \ni 0 = x^n = x \cdot x^{n-1}
\]
By the property of prime ideal, either $x \in P$ or $x^{n-1}$ in $P$. If the former case is true, then we are done; else, we can reduce to the case where either $x \in P$ or $x^{n-2} \in P$. By continuing this process, we finally arrived at either $x \in P$ or $x \in P$, showing that in any cases, $x \in P$. Therefore all nilpotent elements are in $P$, proving the statement. 
\end{pf}

\begin{problem}{III.4.21}
Let $k$ be an algebraic closed field, and let $I \subseteq k[x]$ be an ideal. Prove that $I$ is maximal if and only if $I = (x-c)$ for some $c \in k$.
\end{problem}
\begin{pf}

\noindent $(\Leftarrow)$ We have 
\[
\frac{k[x]}{(x-c)} \cong k 	\quad \text{(p.p.151)}	
\]
and since $k$ is a field, it follows by definition that $(x-c)$ is maximal. \\
$(\Rightarrow)$ Let $J$ be a maximal ideal. By III.4.4, $k[x]$ is a PID, hence every ideal is being generated by a single \emph{monic} polynomial $f(x) \in k[x]$ (III.4.7). Since $k$ is algebraic closed, we can write $f(x) = q(x)(x-c)$ for some $q(x) \in k[x],\; c \in k$. Then  
\[
J = (f(x)) = (q(x)(x-c)) \subseteq (x-c)
\]
and by Proposition III.4.11, either $J = (x-c)$ or $J = k[x]$. The latter case could not happen since the maximal can not be $k[x]$ itself, therefore $J = (x-c)$, as desired. 
\end{pf}

\el

In the following, let $M$ be a (left-)module over $R$.

\section{}

\begin{problem}{III.5.2}
Prove claim 5.1.
\end{problem}
\begin{pf}
Let $\sigma : R \to \text{End}_\mathsf{Ab}(M)$ be a ring homomorphism and $\rho : R \times M \to M$ a function. We verify the following properties:
\begin{itemize}
\setlength\itemsep{0pt}
\item $\rho(r,m+n) = \rho(r,m) + \rho(r,n)$. \\
Note that $\sigma(r)$ is a endomorphism on $M$. Then 
\[
\rho(r,m+n) = \sigma(r)(m+n) = \sigma(r)(m) + \sigma(r)(n) = \rho(r,m) + \rho(r,n)	
\] 
\item $\rho(r+s, m) = \rho(r,m) + \rho(s,m)$. 
\[
\rho(r+s, m) = \sigma(r+s)(m) = \sigma(r)(m) + \sigma(s)(m) = \rho(r,m) + \rho(s,m)
\]
\item $\rho(rs,m) = \rho(r,\rho(s,m))$. 
\[
\rho(rs,m) = \sigma(rs)(m) = \sigma(r)\sigma(s)(m) = \sigma(r)\rho(s,m) = \rho(r,\rho(s,m))
\]
\item $\rho(1,m) = m$. 
\[
\rho(1,m) = \sigma(1)(m) = 1(m) = m	
\]
\end{itemize}
\end{pf}

\begin{problem}{III.5.3}
Prove that $0\cdot m = 0$ and that $(-1) \cdot m = -m$ for all $m \in M$. 
\end{problem}
\begin{pf}
Since $0m = (0+0)m = 0m + 0m, 0m = 0$. Since $0 = 0m = (-1+1)m = (-1)m+m, (-1)m = -m$.
\end{pf}

\begin{problem}{III.5.11}
Let $R$ be commutative. Prove that there is a natural bijection between the set of $R[x]$-module structures on $M$ and $\text{End}_{R-\textsf{Mod}}(M)$.
\end{problem}
\begin{pf}
If $f$ is a $R$-endomorphism $f:M \to M$, then we have to show that there are some suitable maps
\begin{align*}
R[x] \times M &\to M \\
(g(x), \:m) &\to \: ?
\end{align*}
that makes $M$ into a module. We consider $(g(x),m) \to g(f)(m)$, where if $g(x) = \sum_i a_i x^i$, then
\[
g(f)(m) = \sum_{i} a_i f^i(m) \text{ where } f^i = \underbrace{f \circ \cdots \circ f}_{i\text{ times}}
\]
We can easily check by definition that $M$ satisfies the property of $R[x]$-module, so this gives the injectivity of $R[x]$-modules to $\text{End}_{R-\textsf{Mod}}(M)$. To prove surjectivity, if $M$ is a $R[x]$-module, then define $f(m) = xm$. Then $M$ is indeed an endomorphism, proving the statement.
\end{pf}

\begin{problem}{III.5.12}
Let $M,N$ be $R$-modules, and let $\varphi:M \to N$ be a homomorphism of $R$-modules which has a inverse (therefore a bijection). Prove that $\varphi^{-1}$ is also a homomorphism of $R$-modules. Conclude that a bijective $R$-module homomorphism is a $R$-module isomorphism.
\end{problem}
\begin{pf}
Since
\[
\varphi(\varphi^{-1}(m) + \varphi^{-1}(n)) = m + n = \varphi(\varphi^{-1}(m + n))
\]
we have $\varphi^{-1}(m) + \varphi^{-1}(n) = \varphi^{-1}(m + n)$. And
\[
\varphi(r\varphi^{-1}(m)) = r\varphi(\varphi^{-1}(m)) = rm = \varphi(\varphi^{-1}(rm))
\]
so $r\varphi^{-1}(m) = \varphi^{-1}(rm)$ indeed. 
\end{pf}


\begin{problem}{III.5.14}
Prove Proposition 5.18, that is:

\textit{Let $N,P$ be submodules of an $R$-module $M$. Then
\begin{itemize}
\setlength\itemsep{0pt}
\item $N+P$ is a submodule of $M$;
\item $N \cap P$ is a submodule of $P$, and
\[
\frac{N+P}{N} \cong \frac{P}{N \cap P}.	
\]
\end{itemize}
}
\end{problem}
\begin{pf}
Every element of $N+P$ can be written as $n+p$ where $n \in N, p \in P$. Then it is clear that $r(n+p)$ = $rn + rp \in N+P$ for $r \in M$. For the intersection $N \cap P$, it is also clear that for $p \in P, n \in N \cap P$, $pr \in N$ since $r \in N$, and $pr \in P$ since $p \in P$.

The proof for the second isomorphism theorem follows exactly the same as in groups (Proposition II.8.11). Consider the homomorphism
\[
\varphi: P \to \frac{N+P}{N}, \quad \varphi(p) = pN	
\]
it is surjective since for every $(n+p)N$, there is a corresponding $p$. Then
\[
\ker \varphi = \{p \in P : p \in N\} = P \cap N	
\]
then it follows by first isomorphism theorem that 
\[
\frac{N+P}{N} \cong \frac{P}{N \cap P}.
\]
\end{pf}

\section{}

\begin{problem}{III.6.1}
Prove Claim 6.3, that is, $F^R(A) \cong R^{\oplus A}$.
\end{problem}
\begin{pf}
Observe that every element in $R^{\oplus A}$ can be uniquely written as
\[
\sum_{a \in A}r_a \chi(a)	
\]
where $\chi(a) = \chi_a(x)$, the indicator function of $a$, and $r_a \in R$ for $a \in A$. Then it suffices to check the universal property of free modules: given a function $f : A \to M$ where $M$ is a module, we show that the following diagram 
\[
\xymatrix{
&R^{\oplus A} \ar[r]^{\exists ! \varphi} &M \\
&A \ar[ur]^f \ar[u]^{\chi}
}
\]
commutes. Indeed, we define
\[
\varphi\left(\sum_{a \in A}r_a \chi(a)\right) = \sum_{a \in A}r_a f(a)
\]
then the diagram clearly commutes (and is unique). Finally, $\varphi$ is a $R\mathsf{-Mod}$ homomorphism since 
\begin{align*}
\varphi\left(\sum_{a \in A}r_a \chi(a)\right) + \varphi\left(\sum_{a \in A}r_a' \chi(a)\right) = \sum_{a \in A}r_a f(a) + \sum_{a \in A}r_a' f(a)\overset{\checkmark}{=} \sum_{a \in A}(r_a+r_a') f(a) \\
= \varphi\left(\sum_{a \in A}(r_a+r_a') \chi(a)\right) = \varphi\left(\sum_{a \in A}r_a \chi(a) + \sum_{a \in A}r_a' \chi(a)\right)	
\end{align*}
Note that $R$-module's definition gurantees the commutative of $\checkmark$.
\end{pf}

\begin{problem}{III.6.3}
Let $R$ be a ring, $M$ an $R$-module, and $p : M \to M$ an $R$-module homomorphism such that $p^2 = p$. Prove that $M \cong \ker p \oplus \im p$.
\end{problem}
\begin{pf}
We are required to prove that the diagram
\[
\xymatrixcolsep{4pc}
\xymatrix
{
\ker p \ar[dr]^{i_k} \ar@/^/[drr]^{f_k}\\
& M \ar[r]^{\exists!\varphi} &N \\
\im p \ar[ur]_{i_m} \ar@/_/[urr]_{f_m}
}
\]
commutes. Notice that for $x \in \ker p, p(x) = 0$, and
\[
\text{ for } x \in \im p, x - p(x) = p(y) - p(p(y)) = p(y) - p(y) = 0
\]
where $p(y) = x$. This suggest that we define $\varphi$ as 
\[
\varphi(x) = f_k(x - p(x)) + f_m(p(x))
\]
Indeed, if $x \in \ker p$, then $\varphi(x) = f_k(x)$; if $x \in \im p$, then $\varphi(x) = f_m(p(x)) = f_m(x)$ since for $x \in \im p$,
\[
p(y) = x, p(p(y)) = p(y) \Rightarrow p(x) = x.	
\]
But what about $x \in \ker p \cap \im p$? In fact, the only element in the intersection is $0$, as such $x$ must have
\[
x = p(y) = p(p(y)) = p(x) = 0
\]
so $\varphi$ is well-defined. Now it suffices to check that $\varphi$ is a homomorphism, which is direct since $p, f_k$ and $f_m$ are both $R$-homomorphisms, so it preserves the action on $M$ (check yourself if you're not convinced). Therefore by the universal property of coproduct, $\ker p \oplus \im p \cong M$.
\end{pf}

\begin{problem}{III.6.4}
Let $R$ be a ring, and let $n > 1$. View $R^{\oplus(n-1)}$ as a submodule of $R^{\oplus n}$, via the injective homomorphism $R^{\oplus(n-1)} \xhookrightarrow{} R^{\oplus n}$ defined by
\[
(r_1,\dotsc,r_{n-1}) \xhookrightarrow{}	(r_1,\dotsc,r_{n-1}, 0).
\]
Give a one-line proof that
\[
\frac{R^{\oplus n}}{R^{\oplus (n-1)}} \cong R.	
\] 
\end{problem}
\begin{pf}
The surjective map
\[
(r_1,\dotsc,r_{n-1}, r_n) \twoheadrightarrow r_n.
\]
has kernel precisely to $R^{\oplus (n-1)}$, therefore by first isomorphism theorem
\[
\frac{R^{\oplus n}}{R^{\oplus (n-1)}} \cong R.	
\]  
\end{pf}